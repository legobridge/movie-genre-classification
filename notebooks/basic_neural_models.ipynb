{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c05ca4-57cc-44be-a18d-1b6dd034c1ab",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3c1d5c-e603-46b3-8b77-e1a32f015ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3484e51e-2c6e-4c92-96d4-33d076b6dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, GRU, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a70c17e-0f51-48f2-b542-cdab3cbacd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 14:27:24.592373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:24.604254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:24.604409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce3f74-75c2-4b51-87c2-d8c1a7bd1764",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b208b334-9cde-44d5-b1e6-98f86c636735",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>processed_description_string</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oscar et la dame rose</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "      <td>2009</td>\n",
       "      <td>English</td>\n",
       "      <td>listen convers doctor parent 10-year-old oscar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cupid</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "      <td>1997</td>\n",
       "      <td>English</td>\n",
       "      <td>brother sister past incestu relationship curre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Young, Wild and Wonderful</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "      <td>1980</td>\n",
       "      <td>English</td>\n",
       "      <td>bu empti student field trip museum natur histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Secret Sin</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "      <td>1915</td>\n",
       "      <td>English</td>\n",
       "      <td>help unemploy father make end meet edith twin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Unrecovered</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-re...</td>\n",
       "      <td>2007</td>\n",
       "      <td>English</td>\n",
       "      <td>film titl refer un-recov bodi ground zero also...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title     genre  \\\n",
       "id                                          \n",
       "1        Oscar et la dame rose      drama   \n",
       "2                        Cupid   thriller   \n",
       "3    Young, Wild and Wonderful      adult   \n",
       "4               The Secret Sin      drama   \n",
       "5              The Unrecovered      drama   \n",
       "\n",
       "                                          description  year language  \\\n",
       "id                                                                     \n",
       "1    Listening in to a conversation between his do...  2009  English   \n",
       "2    A brother and sister with a past incestuous r...  1997  English   \n",
       "3    As the bus empties the students for their fie...  1980  English   \n",
       "4    To help their unemployed father make ends mee...  1915  English   \n",
       "5    The film's title refers not only to the un-re...  2007  English   \n",
       "\n",
       "                         processed_description_string  \n",
       "id                                                     \n",
       "1   listen convers doctor parent 10-year-old oscar...  \n",
       "2   brother sister past incestu relationship curre...  \n",
       "3   bu empti student field trip museum natur histo...  \n",
       "4   help unemploy father make end meet edith twin ...  \n",
       "5   film titl refer un-recov bodi ground zero also...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/processed/train_data_processed.csv', index_col='id')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def9e374-23dd-438a-b7ee-8948cc85b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48790, 6)\n",
      "(48790, 6)\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-English languages\n",
    "print(train_df.shape)\n",
    "train_df = train_df[train_df['language'] == 'English'].reset_index(drop=True)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8fd8b16-f747-44dd-8bc9-ff44b7801fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>language</th>\n",
       "      <th>processed_description_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48559</th>\n",
       "      <td>Partner to Partner</td>\n",
       "      <td>10</td>\n",
       "      <td>Jack Claves an alcoholic hard edged homicide ...</td>\n",
       "      <td>2011</td>\n",
       "      <td>English</td>\n",
       "      <td>jack clave alcohol hard edg homicid detect tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19346</th>\n",
       "      <td>Shvil Hahalav</td>\n",
       "      <td>0</td>\n",
       "      <td>1964, a village in Galilee. The Mukhtar colla...</td>\n",
       "      <td>1997</td>\n",
       "      <td>English</td>\n",
       "      <td>1964 villag galile mukhtar collabor isra milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>Death of Film</td>\n",
       "      <td>3</td>\n",
       "      <td>Death of Film sings a eulogy for motion pictu...</td>\n",
       "      <td>2008</td>\n",
       "      <td>English</td>\n",
       "      <td>death film sing eulog motion pictur film comin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22954</th>\n",
       "      <td>Rodnye</td>\n",
       "      <td>3</td>\n",
       "      <td>Russian citizen and Soviet-born Ukrainian nat...</td>\n",
       "      <td>2016</td>\n",
       "      <td>English</td>\n",
       "      <td>russian citizen soviet-born ukrainian nativ vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34562</th>\n",
       "      <td>Improv All Stars</td>\n",
       "      <td>4</td>\n",
       "      <td>Drew Carey accompanied by Ryan Stiles, Colin ...</td>\n",
       "      <td>2001</td>\n",
       "      <td>English</td>\n",
       "      <td>drew carey accompani ryan stile colin mochri g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46809</th>\n",
       "      <td>Le naufrage du Princess Sophia</td>\n",
       "      <td>3</td>\n",
       "      <td>This documentary explores the events surround...</td>\n",
       "      <td>2004</td>\n",
       "      <td>English</td>\n",
       "      <td>documentari explor event surround greatest mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39361</th>\n",
       "      <td>\"Family Feud\"</td>\n",
       "      <td>23</td>\n",
       "      <td>Family Feud is a family tv show for all ages,...</td>\n",
       "      <td>2014</td>\n",
       "      <td>English</td>\n",
       "      <td>famili feud famili tv show age whole famili en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39021</th>\n",
       "      <td>Meng xing shi fen</td>\n",
       "      <td>0</td>\n",
       "      <td>Ma Lei which sounds like \"Mary\" is a Chinese ...</td>\n",
       "      <td>1992</td>\n",
       "      <td>English</td>\n",
       "      <td>lei sound like mari chines citizen live hong k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958</th>\n",
       "      <td>Shanka</td>\n",
       "      <td>0</td>\n",
       "      <td>This story is about an honest police officer ...</td>\n",
       "      <td>1993</td>\n",
       "      <td>English</td>\n",
       "      <td>stori honest polic offic amit sen wife seema s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18482</th>\n",
       "      <td>Brush with Life: The Art of Being Edward Bibe...</td>\n",
       "      <td>3</td>\n",
       "      <td>Edward Biberman's groundbreaking depictions o...</td>\n",
       "      <td>2007</td>\n",
       "      <td>English</td>\n",
       "      <td>edward biberman groundbreak depict southern ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48790 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  genre  \\\n",
       "48559                                Partner to Partner      10   \n",
       "19346                                     Shvil Hahalav       0   \n",
       "3676                                      Death of Film       3   \n",
       "22954                                            Rodnye       3   \n",
       "34562                                  Improv All Stars       4   \n",
       "...                                                  ...    ...   \n",
       "46809                    Le naufrage du Princess Sophia       3   \n",
       "39361                                     \"Family Feud\"      23   \n",
       "39021                                 Meng xing shi fen       0   \n",
       "13958                                            Shanka       0   \n",
       "18482   Brush with Life: The Art of Being Edward Bibe...      3   \n",
       "\n",
       "                                             description  year language  \\\n",
       "48559   Jack Claves an alcoholic hard edged homicide ...  2011  English   \n",
       "19346   1964, a village in Galilee. The Mukhtar colla...  1997  English   \n",
       "3676    Death of Film sings a eulogy for motion pictu...  2008  English   \n",
       "22954   Russian citizen and Soviet-born Ukrainian nat...  2016  English   \n",
       "34562   Drew Carey accompanied by Ryan Stiles, Colin ...  2001  English   \n",
       "...                                                  ...   ...      ...   \n",
       "46809   This documentary explores the events surround...  2004  English   \n",
       "39361   Family Feud is a family tv show for all ages,...  2014  English   \n",
       "39021   Ma Lei which sounds like \"Mary\" is a Chinese ...  1992  English   \n",
       "13958   This story is about an honest police officer ...  1993  English   \n",
       "18482   Edward Biberman's groundbreaking depictions o...  2007  English   \n",
       "\n",
       "                            processed_description_string  \n",
       "48559  jack clave alcohol hard edg homicid detect tea...  \n",
       "19346  1964 villag galile mukhtar collabor isra milit...  \n",
       "3676   death film sing eulog motion pictur film comin...  \n",
       "22954  russian citizen soviet-born ukrainian nativ vi...  \n",
       "34562  drew carey accompani ryan stile colin mochri g...  \n",
       "...                                                  ...  \n",
       "46809  documentari explor event surround greatest mar...  \n",
       "39361  famili feud famili tv show age whole famili en...  \n",
       "39021  lei sound like mari chines citizen live hong k...  \n",
       "13958  stori honest polic offic amit sen wife seema s...  \n",
       "18482  edward biberman groundbreak depict southern ca...  \n",
       "\n",
       "[48790 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_genres = train_df['genre'].unique()\n",
    "genre_encoding = dict([(unique_genres[i], i) for i in range(unique_genres.shape[0])])\n",
    "train_df['genre'] = train_df['genre'].map(genre_encoding)\n",
    "train_df = train_df.sample(frac=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94b741d1-8175-4b7c-91c8-ff151d4d0e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = train_df['genre'].nunique()\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6170baee-9fe2-41e0-8694-40ce00bb3d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df['processed_description_string'].values\n",
    "y = pd.get_dummies(train_df['genre']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66f6cd8-8b38-4061-b155-a6ee802bf9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = 45000\n",
    "val_set_size = 3000\n",
    "test_set_size = 5000\n",
    "\n",
    "x_train = x[:train_set_size]\n",
    "x_val = x[train_set_size:train_set_size+val_set_size]\n",
    "x_test = x[train_set_size+val_set_size:train_set_size+val_set_size+test_set_size]\n",
    "\n",
    "y_train = y[:train_set_size]\n",
    "y_val = y[train_set_size:train_set_size+val_set_size]\n",
    "y_test = y[train_set_size+val_set_size:train_set_size+val_set_size+test_set_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613c1f0c-639a-4d43-8994-8e5e4020664e",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18604f3f-ef64-47a3-8f0a-ece2358dc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 2**9\n",
    "max_len = 2**5\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_val = pad_sequences(x_val, maxlen=max_len)\n",
    "\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b83df-6297-4028-9867-13015e77c8d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60c5fd39-9263-4f8c-b14e-1a7b33fa3d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 14:27:33.254635: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 14:27:33.255261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:33.255426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:33.255529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:33.566934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:33.567092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:33.567199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 14:27:33.567336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6425 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# model = load_model('../models/nn_model')\n",
    "model = Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "210e306e-8bc7-4898-995e-ae52e2525b43",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 26.8505 - accuracy: 0.1627 - val_loss: 3.6347 - val_accuracy: 0.2390\n",
      "Epoch 2/50\n",
      "1407/1407 [==============================] - 2s 2ms/step - loss: 3.7050 - accuracy: 0.1971 - val_loss: 2.4440 - val_accuracy: 0.2713\n",
      "Epoch 3/50\n",
      " 398/1407 [=======>......................] - ETA: 1s - loss: 2.7688 - accuracy: 0.2290"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m my_callbacks  \u001b[38;5;241m=\u001b[39m [EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                               min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      3\u001b[0m                               patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      4\u001b[0m                               mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmy_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/engine/training.py:1389\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs  \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1389\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1391\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/utils/tf_utils.py:563\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/keras/utils/tf_utils.py:557\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    555\u001b[0m   \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 557\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m   \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/jupyter/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1190\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_callbacks  = [EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              mode='auto')]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=50, batch_size=32,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=my_callbacks,\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdefc411-e534-472f-bad8-809842980b04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "124155d6-3b04-4bcf-984f-b57240047044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step - loss: 2.3386 - accuracy: 0.2648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.338596820831299, 0.2648000121116638]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f19bf30e-fbe3-494a-bf2c-09c03894abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/nn_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/nn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f717d2-41c2-4ca6-8e75-a862d6c85f04",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GRU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b1c06b1-f06b-4ed0-b105-1c10fe4f6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 2**5\n",
    "\n",
    "# model = load_model('../models/gru_model')\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, EMBEDDING_DIM, input_length=x_train.shape[1]))\n",
    "model.add(GRU(256, dropout=0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93151ace-c098-4b88-a5e3-d30e0200d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9942 - accuracy: 0.4173 - val_loss: 1.8444 - val_accuracy: 0.4663\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7505 - accuracy: 0.4852 - val_loss: 1.7316 - val_accuracy: 0.4960\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6726 - accuracy: 0.5008 - val_loss: 1.6832 - val_accuracy: 0.5020\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6210 - accuracy: 0.5092 - val_loss: 1.6442 - val_accuracy: 0.5110\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5802 - accuracy: 0.5177 - val_loss: 1.6438 - val_accuracy: 0.5057\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5437 - accuracy: 0.5258 - val_loss: 1.6093 - val_accuracy: 0.5113\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5101 - accuracy: 0.5329 - val_loss: 1.6089 - val_accuracy: 0.5103\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4785 - accuracy: 0.5390 - val_loss: 1.6239 - val_accuracy: 0.5103\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4541 - accuracy: 0.5469 - val_loss: 1.6208 - val_accuracy: 0.5133\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.4113 - accuracy: 0.5548 - val_loss: 1.6182 - val_accuracy: 0.5077\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3729 - accuracy: 0.5653 - val_loss: 1.6388 - val_accuracy: 0.5070\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.3270 - accuracy: 0.5778 - val_loss: 1.6782 - val_accuracy: 0.5020\n"
     ]
    }
   ],
   "source": [
    "my_callbacks  = [EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=5,\n",
    "                              mode='auto')]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20, batch_size=32,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=my_callbacks,\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a18af-7552-4b75-ae6c-79ab0fbe355a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GRU Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a344ab72-728b-4a5f-929f-0ab55c350ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6494 - accuracy: 0.5190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.649399757385254, 0.5189999938011169]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "075d9669-d3b6-467f-8128-1faccf2daf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/gru_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/gru_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7ff436607dc0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/gru_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f6b6a-7209-4ddb-900c-db9eca5878fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36526f8a-ee11-4206-9b79-df208ef193f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 2**5\n",
    "\n",
    "# model = load_model('../models/lstm_model')\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, EMBEDDING_DIM, input_length=x_train.shape[1]))\n",
    "model.add(LSTM(64, dropout=0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "057cbd29-de46-4520-a226-b664a7183d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 2.0685 - accuracy: 0.4032 - val_loss: 1.8698 - val_accuracy: 0.4660\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.8112 - accuracy: 0.4678 - val_loss: 1.8031 - val_accuracy: 0.4823\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.7408 - accuracy: 0.4872 - val_loss: 1.7328 - val_accuracy: 0.4977\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6787 - accuracy: 0.5015 - val_loss: 1.7270 - val_accuracy: 0.4940\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6402 - accuracy: 0.5088 - val_loss: 1.7068 - val_accuracy: 0.5003\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.6111 - accuracy: 0.5139 - val_loss: 1.6700 - val_accuracy: 0.5007\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5845 - accuracy: 0.5200 - val_loss: 1.6402 - val_accuracy: 0.5027\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5604 - accuracy: 0.5252 - val_loss: 1.6456 - val_accuracy: 0.4977\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5400 - accuracy: 0.5285 - val_loss: 1.6289 - val_accuracy: 0.5147\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 1.5221 - accuracy: 0.5316 - val_loss: 1.6266 - val_accuracy: 0.5123\n"
     ]
    }
   ],
   "source": [
    "my_callbacks  = [EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              mode='auto')]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10, batch_size=32,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=my_callbacks,\n",
    "                    verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfb1e0-4b89-4744-b76f-747b3bafba22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6877371f-f1e6-437a-8976-642caa31252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6114 - accuracy: 0.5172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.611369252204895, 0.5171999931335449]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85ef9f67-7a21-4f7b-9635-e49bd1a21d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/lstm_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/lstm_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7ff3f07153a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/lstm_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
